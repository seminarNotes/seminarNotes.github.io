# Site
repository: Git repository where your resume will be hosted, only required if you are hosting on GitHub (eg. sproogen/modern-resume-theme)
# favicon: Directory of your favicon (eg. images/favicon.ico)(optional)

# Content configuration version
version: 2

# Personal info
name: 우준희
title: Jr. Data Engineer
email: junhui.woo.math@gmail.com
# email_title: Email (Email title override)
# phone: Your phone number (optional)
# phone_title: Phone (Phone title override)
website: https://github.com/seminarNotes
# website_title: Web (Website title override)

# Dark Mode (true/false/never)
darkmode: true

# Social links
# twitter_username: jekyllrb
github_username:  seminarNotes
# stackoverflow_username: "00000001"
# dribbble_username: jekyll
# facebook_username: jekyll
# flickr_username: jekyll
linkedin_username: 준희-우-bb8472289
instagram_username: woojunhui
# xing_username: jekyll
# pinterest_username: jekyll
# youtube_username: jekyll
# orcid_username: 0000-0000-0000-0000
# googlescholar_username: D847cGsAAAAJ

# Additional icon links
# additional_links:
# - title: Link name
#   icon: Font Awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&s=brands&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
# about_title: About Me (Use this to override about section title)
about_profile_image: images/blog_profile.jpg #Directory of profile image (eg. images/profile.jpg)
about_content: | # this will include new lines to allow paragraphs
  👋 Hello   
  안녕하세요, 저는 2년 차 데이터 엔지니어 우준희입니다. 저는 석사 과정에서 수학(파생상품 평가)을 전공하였습니다. 이러한 배경을 바탕으로 제 첫 직장에서 금융 데이터 분석 분야에 발을 들였고, 시장 가격을 수집, 저장, 모델링하는 업무를 맡게 되었습니다. 이 과정에서 데이터 수집, 가공, 저장, 모델링, 시각화, 메일링 등의 작업을 수행하기 위해 Python(특히 Celery, apscheduler, win32com 라이브러리), 그리고 Oracle과 MariaDB와 같은 DBMS를 학습하고 업무를 수행하였습니다. 이 경험이 저를 데이터 엔지니어링이라는 길로 이끌었습니다.

  현재는 우리FIS 아카데미의 AI엔지니어링 과정을 데이터 엔지니어링을 공부하고 있으며, 교육 과정에서 Python, JAVA(Spring), ELK, AWS, Docker 등 데이터 분석 및 처리, 데이터 파이프라인 구축에 필요한 다양한 기술 학습을 진행 중입니다. 교육과 별개로, 데이터 엔지니어로서의 성장을 목표로 Cloudera 기반의 Hadoop Ecosystem 구축에도 도전했습니다. 이를 통해 Flume, Kafka, Storm, Esper, HDFS, Redis, HBase, Hue를 활용하여 실시간 및 대용량 데이터 처리와 저장을 위한 파이프라인을 구축했습니다. 또한, ELK 스택을 이용해 가상의 로그 데이터를 처리하고, Airflow와 Superset을 활용하여 크롤링한 데이터를 시각화하는 프로젝트를 진행했습니다.

  저는 새로운 기술을 접하는 것에 주저하지 않으며, 자신감을 가지고 문제를 해결해 나가는 과정에서 조직에 기여하고자 합니다. 이러한 다양한 경험을 통해 제가 보다 심도 있는 데이터 엔지니어링 역량을 갖출 수 있도록 노력하고 있습니다.

  🏃Current tasks in progress
  
  - [Cloudera를 통한 Hadoop Ecosystem 구축](https://github.com/seminarNotes/engineering--smartcar-real-time-log-processing)
  
  👨🏻‍💻Software
  - Python  
    ML 모델 학습 및 하이퍼 파라미터 튜닝  
    업무 자동화 및 스케줄링, Celery를 활용하여 분산 처리  
    대규모 데이터 분석, DB 테이블 적재  

  - DBMS  
    Mysql, MariaDB, Oracle
    
  - Airflow 
    Workflow 정의 및 스케줄

  - Elastic Stack  
    Log 데이터 수집 및 시각화

  - Linux, Docker
    
  👨‍🎓Expertise
  - Mathematics  
    데이터 분석에 필요한 선형대수학과 통계학에 대한 지식  
    데이터 모델링과 수치해석에 대한 지식(모델링, 모수 추정)  
    Backpropagation 등과 같은 ML의 이론을 이해하는 전반적 수학지식  

  - Computer Science  
    Linux와 Docker 활용  
    데이터 구조 및 데이터베이스 관리 시스템(DBMS)  
    빅데이터 기술과 클라우드 컴퓨팅  
    
content:
  - title: pilot Projects 💻 # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        border: weak  # Value of `weak` will display a weak border below this item. # Any 
                      # other value (or no value) means no border will be displayed
        title: Project1:Engineering
        link: https://github.com/seminarNotes/engineering--smartcar-real-time-log-processing/blob/main/Pilotproject.md
        link_text: Go to the link for Project1
        additional_links:
          - title: seminarNotes/engineering--smartcar-real-time-log-processing
            icon: fab fa-github
            url: https://github.com/seminarNotes/engineering--smartcar-real-time-log-processing/blob/main/Pilotproject.md
        quote: >
           Implementing Real-time Big Data Processing for Vehicle Status Monitoring from IoT Sensors in Smart Cars
        description: | # this will include new lines to allow paragraphs
          이 프로젝트는 스마트카에 탑재된 수백 개의 IoT 센서로부터 자동차 상태 정보를 실시간으로 모니터링하고 수집하여, 이를 처리 및 분석하는 빅데이터 처리 과제입니다. 각 단계별로 필요한 요구사항을 면밀히 분석한 뒤, 요구 사항을 해결하기 위해 적절한 기술 스택을 선정하여 프로젝트를 성공적으로 구현했습니다. 배치 데이터 처리의 경우, Flume과 HDFS를 활용했으며, 실시간 스트리밍 데이터는 Flume, Kafka, Esper, Storm, Redis를 통해 효율적으로 적재했습니다. 또한, 데이터 마트 구축에는 HBase를 사용했고, 이 과정을 용이하게 만들기 위해 Hue를 통한 브라우저 접근과 Oozie를 이용한 워크플로우 관리를 도입하여 데이터 마트를 구축하고 데이터 적재 작업을 수행했습니다.  
          
          - Related Images:  
            <img src="/images/pjt1_images1.jpg" alt="pjt1_images1" width="350" height="250">
            <img src="/images/pjt1_images2.jpg" alt="pjt1_images2" width="350" height="250">

          - Related Stacks:  
            <img src="https://img.shields.io/badge/Apache Hadoop-66CCFF?style=for-the-badge&amp;logo=Apache Hadoop&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/Apache Hive-FDEE21?style=for-the-badge&amp;logo=Apache Hive&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/Apache Kafka-231F20?style=for-the-badge&amp;logo=Apache Kafka&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/Apache Spark-E25A1C?style=for-the-badge&amp;logo=Apache Spark&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/Apache Storm-225593?style=for-the-badge&amp;logo=Apache Storm&amp;logoColor=white"> 
          
            <img src="https://img.shields.io/badge/Cloudera-F96702?style=for-the-badge&amp;logo=Cloudera&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/FileZilla-BF0000?style=for-the-badge&amp;logo=FileZilla&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/CentOS-262577?style=for-the-badge&amp;logo=CentOS&amp;logoColor=white"> 
            <img src="https://img.shields.io/badge/Spring-6DB33F?style=for-the-badge&amp;logo=Spring&amp;logoColor=white"> 

      - layout: left
        border: weak  # Value of `weak` will display a weak border below this item. # Any 
                      # other value (or no value) means no border will be displayed
        title: Project2:Engineering
        link: https://github.com/seminarNotes/engineering--program-real-time-log-processing
        link_text: Go to the link for Project2
        additional_links:
          - title: engineering--program-real-time-log-processing
            icon: fab fa-github
            url: https://github.com/seminarNotes/engineering--program-real-time-log-processing
        quote: >
           Efficient Real-time Log Data Monitoring and Analysis Using the ELK Stack and Python
        description: | # this will include new lines to allow paragraphs
          다양한 프로그램, 사물, 애플리케이션은 지속적으로 로그 데이터를 생성하며, 이 데이터는 대부분 실시간으로 모니터링되어 필요한 조치가 취해져야 합니다. 이 과정에서 ELK Stack과 Elasticsearch는 데이터의 처리, 모니터링, 분석, 그리고 시각화를 위한 필수적인 도구로 자리 잡고 있습니다. 특히, 비정형 데이터의 관리 및 분석에 있어서 중요한 역할을 합니다. 이러한 맥락에서, Python을 사용하여 가상의 로그 데이터를 생성하고, 이 데이터를 실시간으로 추출하기 위해 Beats를 활용했습니다. 또한, Logstash를 이용해 로그 패턴을 분석한 뒤, 이 데이터를 Elasticsearch(NoSQL 데이터베이스)에 저장했습니다. 저장된 데이터는 Kibana를 사용하여 시각화함으로써, 사용자가 쉽게 인사이트를 얻을 수 있도록 했고, 실시간 로그 데이터에 대한 즉각적인 정보 제공을 위해 Kibana 대시보드를 구성했습니다. 이 전체 과정은 실시간 데이터 모니터링과 분석에 있어서 매우 효과적인 시스템을 구축하는 데 기여했습니다.    
          
          - Related Images:               
            <img src="/images/pjt2_images1.jpg" alt="pjt2_images1" width="350" height="250">
            <img src="/images/pjt2_images2.jpg" alt="pjt2_images2" width="350" height="250">

          - Related Stacks:               
            <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white"> 
            <img src="https://img.shields.io/badge/Beats-005571?style=for-the-badge&logo=Beats&logoColor=white"> 
            <img src="https://img.shields.io/badge/Logstash-85C8C8?style=for-the-badge&logo=Logstash&logoColor=white">
            <img src="https://img.shields.io/badge/Elasticsearch-005571?style=for-the-badge&logo=Elasticsearch&logoColor=white">
            <img src="https://img.shields.io/badge/Kibana-005571?style=for-the-badge&logo=Kibana&logoColor=white">  

      - layout: left
        border: weak  # Value of `weak` will display a weak border below this item. # Any 
                      # other value (or no value) means no border will be displayed
        title: Project3:Orchestration 
        link: https://github.com/seminarNotes/analysis--hyperparameter-tuning-lstm
        link_text: Go to the link for Project3
        additional_links:
          - title: seminarNotes/analysis--hyperparameter-tuning-lstm
            icon: fab fa-github
            url: https://github.com/seminarNotes/analysis--hyperparameter-tuning-lstm
        quote: >
          Training and Validation of LSTM Model with Hyperparameter Tuning
        description: | # this will include new lines to allow paragraphs
          하이퍼파라미터 튜닝은 머신러닝 모델의 성능을 최적화하기 위해 모델의 하이퍼파라미터를 조정하는 프로세스입니다.
          이 과정은 반복적이고 시행착오(Trials and errors)적이기 때문에 효율적으로 튜닝을 하기 위해 탐색 공간을 정의하여 데이터베이스에 저장하였고, 이를 바탕으로 학습과 모델 평가를 수행하였습니다.
          또한, 작업 스케줄링을 위한 데이터베이스 테이블을 정의하여 각 작업을 순차적으로 모니터링할 수 있도록 구성하였습니다.
          
           <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
           <img src="https://img.shields.io/badge/tensorflow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"> 
           <img src="https://img.shields.io/badge/Mysql-4479A1?style=for-the-badge&logo=Mysql&logoColor=white"> 
           
      - layout: left
        border: weak  # Value of `weak` will display a weak border below this item. # Any 
                      # other value (or no value) means no border will be displayed
        title: Project4:Analysis
        link: https://github.com/seminarNotes/analysis--customer-lifetime-value
        link_text: Go to the link for Project4
        additional_links:
          - title: seminarNotes/analysis--customer-lifetime-value
            icon: fab fa-github
            url: https://github.com/seminarNotes/analysis--customer-lifetime-value
        quote: >
          Analyzing Customer Data and Retail Data for LTV (Lifetime Value) and EDA (Exploratory Data Analysis)
        description: | # this will include new lines to allow paragraphs
          본 프로젝트의 목표는 소매 및 고객 데이터를 분석하여 고객의 생애 가치를 평가하고, 이를 시각화하여 Streamlit을 활용한 대시보드에서 제공하는 것이었습니다. 이를 통해 기업이 고객 관계 관리 전략을 최적화할 수 있도록 지원하는 것이 주된 목표였습니다. 고객 데이터에 대한 심층 분석을 수행하여, 개별 고객의 생애 가치를 계산했습니다. 이 과정에서, 수명주기 기반 모델인 BG/NBD 모델과 고객 가치의 통계적 분포를 모델링하는 Gamma-Gamma 모델을 적용하였습니다. 분석의 정확성을 높이기 위해, 모수 추정 과정을 실시했습니다. 이 단계에서는 주어진 데이터 세트에 모델을 적합시키고, 모델의 매개변수를 최적화하여 분석 결과의 신뢰도를 향상시켰습니다. Streamlit 라이브러리를 활용하여, 분석 결과를 직관적으로 이해할 수 있는 대시보드를 개발했습니다. 대시보드는 고객별 생애 가치 예측, 고객 세분화 결과, 그리고 고객 행동 분석 결과를 시각화하여 제공합니다.
          
          - Related Images:  
            <img src="/images/pjt4_images1.jpg" alt="pjt4_images1" width="350" height="250">
            <img src="/images/pjt4_images2.jpg" alt="pjt4_images2" width="350" height="250"> 

          - Related Stacks:  
            <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
            <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white">
        
  - title: Experience 📰
    layout: list
    content:
      - layout: left
        title: KIS pricing INC
        sub_title: Analyst
        caption: Dec 1st, 2021 - Aug 8th, 2023
        link: https://www.bond.co.kr/
        # quote: >
        #  Short description of the company (optional)
        description: | # this will include new lines to allow paragraphs
          주식 파생상품과 신용 파생상품 평가 로직에 대해 조사를 하고 관련된 모듈을 개발 및 유지보수를 했습니다. 
          제가 주로 맡았던 프로젝트는 다음과 같습니다.  
          
          - **Python을 이용한 데이터 파이프라인 구축**  
            - Duration:  
              2022.04. - 2022.07.  
            - Responsibilities/Achievements:  
              ICE connect라는 유료 서비스를 사용하여 옵션 가격 데이터를 수집하는 과정에서 발생한 데이터의 양과 질, 그리고 잦은 접속 오류 문제를 해결하기 위해 다른 금융정보 서비스인 CHECK Expert+로 전환하였습니다. 이를 위해 파이썬을 사용하여 한국 거래소에서 당일 거래된 옵션의 발행 정보를 크롤링하고, CHECK Expert의 엑셀 프리미엄 기능을 활용하여 데이터를 조회한 후, 조회된 데이터를 DB에 저장하는 데이터 수집 프로세스를 구축했습니다. 이 과정은 Celery를 사용하여 자동화되었으며, 이를 통해 분기당 약 8,268GBP(한화 약 1,340만원)을 절감하고, 유의미한 데이터를 24.45% 추가로 확보하는 성과를 달성했습니다.  
            - Related Stacks:  
              <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
              <img src="https://img.shields.io/badge/Celery-37814A?style=for-the-badge&logo=Celery&logoColor=white"> 
              <img src="https://img.shields.io/badge/MariaDB-003545?style=for-the-badge&logo=MariaDB&logoColor=white"> 
              <img src="https://img.shields.io/badge/Oracle-F80000?style=for-the-badge&logo=Oracle&logoColor=white"> 
              <img src="https://img.shields.io/badge/microsoftexcel-217346?style=for-the-badge&logo=microsoftexcel&logoColor=white">
 
          - **데이터 모델(주식 변동성 평가 모델) 구축**  
            - Duration:  
              2022.07. - 2023.02.  
            - Responsibilities/Achievements:  
              기존의 주식 변동성 평가 모델을 파이썬으로 재구현하여 모수 추정 과정의 시간적 비용을 줄이고, Excel 충돌 문제를 해결했습니다. 새로운 모델 구현으로 모수의 수를 8개에서 3개로 줄이고, 보정 과정의 기준을 확립하여 적절한 결과값이 나올 때까지 모수 추정을 반복하도록 엔진 로직을 변경했습니다. 또한, 결과값을 pyTelegramBotAPI를 활용해 메신저로 확인할 수 있게 하고, DB에 저장하여 Excel VBA를 통한 UI로 데이터를 로드/저장할 수 있게 개선했습니다. 이 작업을 통해 하나의 Excel만으로 DB로부터 데이터를 로드할 수 있게 되어 서버의 저장 비용을 줄였습니다.  
            - Related Stacks:  
              <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
              <img src="https://img.shields.io/badge/MariaDB-003545?style=for-the-badge&logo=MariaDB&logoColor=white">
              <img src="https://img.shields.io/badge/Oracle-F80000?style=for-the-badge&logo=Oracle&logoColor=white">
              <img src="https://img.shields.io/badge/microsoftexcel-217346?style=for-the-badge&logo=microsoftexcel&logoColor=white">
    
          - **데이터 계산 엔진 및 데이터 검증 시스템 개선**  
            - Duration:  
              2022.11. - 2023.07.  
            - Responsibilities/Achievements:  
              부도율 산출 프로세스 엔진을 보수하고 데이터 검증 시스템을 개선했습니다. Python을 사용해 DB에서 대량의 데이터를 로드하고, 평가 모듈(DLL)에 입력한 후 산출된 값을 다시 DB에 저장하는 시스템을 구현했습니다. 이를 통해 데이터 오염 문제를 해결하고, 평가 모듈에서 중간 계산값을 출력할 수 있도록 수정하여 데이터 검증 과정을 강화했습니다.  
            - Related Stacks:    
              <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white"> 
              <img src="https://img.shields.io/badge/C-A8B9CC?style=for-the-badge&logo=C&logoColor=white"> 
              <img src="https://img.shields.io/badge/MariaDB-003545?style=for-the-badge&logo=MariaDB&logoColor=white"> 
              <img src="https://img.shields.io/badge/Oracle-F80000?style=for-the-badge&logo=Oracle&logoColor=white"> 
              <img src="https://img.shields.io/badge/sourcetree-0052CC?style=for-the-badge&logo=sourcetree&logoColor=white"> 
              
              <img src="https://img.shields.io/badge/microsoftexcel-217346?style=for-the-badge&logo=microsoftexcel&logoColor=white">
              <img src="https://img.shields.io/badge/Notepad++-90E59A.svg?style=for-the-badge&logo=notepad%2B%2B&logoColor=white"> 

  - title: Education 📚
    layout: list
    content:
      - layout: left
        title: Woori FISA
        sub_title: AI Enginnering
        caption: Nov, 2023 - Present(until May, 2024)
        link: https://woorifisa.com/
        quote: >
          Studying data analysis, engineering and related software.
        description: | # this will include new lines to allow paragraphs
          현재는 우리FIS 아카데미의 AI엔지니어링 과정을 데이터 엔지니어링을 공부하고 있으며, 교육 과정에서 Python, JAVA(Spring), ELK, AWS, Docker 등 데이터 분석 및 처리, 데이터 파이프라인 구축에 필요한 다양한 기술 학습을 진행 중입니다.

          <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
          <img src="https://img.shields.io/badge/Mysql-4479A1?style=for-the-badge&logo=Mysql&logoColor=white"> 
          <img src="https://img.shields.io/badge/pandas-150458?style=for-the-badge&logo=pandas&logoColor=white"> 
          <img src="https://img.shields.io/badge/numpy-013243?style=for-the-badge&logo=numpy&logoColor=white"> 
          <img src="https://img.shields.io/badge/tensorflow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white"> 

          <img src="https://img.shields.io/badge/java-007396?style=for-the-badge&logo=java&logoColor=white"> 
          <img src="https://img.shields.io/badge/linux-FCC624?style=for-the-badge&logo=linux&logoColor=white"> 
          <img src="https://img.shields.io/badge/docker-2496ED?style=for-the-badge&logo=docker&logoColor=white"> 
          <img src="https://img.shields.io/badge/Amazon AWS-232F3E?style=for-the-badge&logo=Amazon AWS&logoColor=white"> 
          <img src="https://img.shields.io/badge/Elastic Stack-005571?style=for-the-badge&logo=Elastic Stack&logoColor=white"> 

      - layout: left
        title: Pusan Natl. Univ.
        sub_title: M.S. with Mathematics
        caption: Sep, 2017 - Feb, 2019
        quote: >
          Studying mathematics, financial engineering, and related programming.
        description: | # this will include new lines to allow paragraphs
          수학과에서 금융 수학을 공부했으며, 파생상품 옵션 평가(Option Pricing)에 대해 연구하였습니다. 특히, 주식 또는 변동성의 움직임을 모델링하는 확률미분방정식에 대해 연구를 하고, 관련된 논문을 작성했습니다.
          또한, 몬테카를로 시뮬레이션과(Monte-Carlo Simulation)과 유한차분법(Finite Difference Method)을 이용한 옵션 가격 결정을 프로그래밍으로 구현하였습니다.

          <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white">
          <img src="https://img.shields.io/badge/Latex-008080?style=for-the-badge&logo=Latex&logoColor=white">
          
      - layout: left
        title: Inha Univ.
        sub_title: B.S. with Math edu.
        caption: May, 2013 - Feb, 2017
        quote: >
          Studying mathematics including matrix theory and numerical analysis.
        description: | # this will include new lines to allow paragraphs
          수학교육과에서 Excel을 활용하여 기본적인 통계량을 계산하는 실습을 학습하였고, 미분방정식의 해를 찾거나 최적화를 위한 수치 계산에 대해 공부하였습니다.

          <img src="https://img.shields.io/badge/wolframmathematica-DD1100?style=for-the-badge&logo=wolframmathematica&logoColor=white">
          <img src="https://img.shields.io/badge/matrix-000000?style=for-the-badge&logo=matrix&logoColor=white">
          <img src="https://img.shields.io/badge/microsoftexcel-217346?style=for-the-badge&logo=microsoftexcel&logoColor=white">
    
  - title: Publications 📝
    layout: text
    content: | # this will include new lines to allow paragraphs
      - Junhui, U., Donghyun Kim, and Ji-Hun Yoon. "The pricing of vulnerable options under a constant elasticity of variance model." Journal of the Chungcheong Mathematical Society 33.2 (2020): 181-195.    
      - Kim, Donghyun, Junhui Woo, and Ji-Hun Yoon. "Pricing American lookback options under a stochastic volatility model." Bulletin of the Korean Mathematical Society (2023), 361-388.

  - title: Awards 🏆
    layout: text
    content: |
      - Academic award, College of Natural Sciences, Pusan National University, 2020.05.29.    
      - Commendation letter, Republic of Korea Army Logistics Command, 2019.06.28.

  
  # - title: Awards
  #   layout: text
  #   content:  # this will include new lines to allow paragraphs
  #   - layout: left
  #       description: |
  #         - 'Academic award, College of Natural Sciences, Pusan National University, 2020.05.29.'    
  #         - 'Commendation letter, Republic of Korea Army Logistics Command, 2019.06.28.'

    

# Footer
footer_show_references: true
# references_title: References on request (Override references text)

# Build settings
# theme: modern-resume-theme (Use this is you are hosting your resume yourself)
# remote_theme: sproogen/modern-resume-theme (Use this if you are hosting your resume on GitHub)

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
